{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/MagicAnimate-colab/blob/main/DensePose_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!wget https://huggingface.co/camenduru/densepose/raw/main/Base-DensePose-RCNN-FPN.yaml -O /content/Base-DensePose-RCNN-FPN.yaml\n",
        "!wget https://huggingface.co/camenduru/densepose/raw/main/densepose_rcnn_R_50_FPN_s1x.yaml -O /content/densepose_rcnn_R_50_FPN_s1x.yaml\n",
        "!pip install -q gradio \n",
        "!pip install -q https://huggingface.co/camenduru/densepose/resolve/main/detectron2-0.6-cp310-cp310-linux_x86_64.whl?download=true\n",
        "!pip install -q https://huggingface.co/camenduru/densepose/resolve/main/detectron2_densepose-0.6-py3-none-any.whl?download=true\n",
        "\n",
        "import gradio as gr\n",
        "from detectron2.config import get_cfg\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from densepose import add_densepose_config\n",
        "from densepose.vis.extractor import DensePoseResultExtractor\n",
        "from densepose.vis.densepose_results import DensePoseResultsFineSegmentationVisualizer as Visualizer\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "def process_video(input_video_path):\n",
        "    output_video_path = tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False).name\n",
        "    cfg = get_cfg()\n",
        "    add_densepose_config(cfg)\n",
        "    cfg.merge_from_file(\"/content/densepose_rcnn_R_50_FPN_s1x.yaml\")\n",
        "    predictor = DefaultPredictor(cfg)\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        with torch.no_grad():\n",
        "            outputs = predictor(frame)['instances']\n",
        "        results = DensePoseResultExtractor()(outputs)\n",
        "        cmap = cv2.COLORMAP_VIRIDIS\n",
        "        arr = cv2.applyColorMap(np.zeros((height, width), dtype=np.uint8), cmap)\n",
        "        out_frame = Visualizer(alpha=1, cmap=cmap).visualize(arr, results)        \n",
        "        out.write(out_frame)\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    return output_video_path\n",
        "iface = gr.Interface(\n",
        "    fn=process_video,\n",
        "    inputs=gr.Video(label=\"Input Video\"),\n",
        "    outputs=gr.Video(label=\"Output DensePose Video\"),\n",
        "    title=\"Video 2 DensePose\"\n",
        ")\n",
        "iface.launch(share=True, inline=False, debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
